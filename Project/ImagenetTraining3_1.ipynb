{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d57136e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: onedrivedownloader in c:\\users\\amughal23\\appdata\\roaming\\python\\python39\\site-packages (1.1.3)\n",
      "Requirement already satisfied: tqdm in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from onedrivedownloader) (4.64.1)\n",
      "Requirement already satisfied: requests in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from onedrivedownloader) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from requests->onedrivedownloader) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from requests->onedrivedownloader) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from requests->onedrivedownloader) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from requests->onedrivedownloader) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from tqdm->onedrivedownloader) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import tarfile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as utils\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import time\n",
    "\n",
    "try:\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# If you encounter some issues regarding cuda device, e.g., \"RuntimeError: CUDA Out of memory error\",\n",
    "# try to switch the device to cpu by using the following code\n",
    "\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "print('Device:', device)\n",
    "\n",
    "\n",
    "!pip install onedrivedownloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd479e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open('./train.tar', 'r') as td:\n",
    "    td.extractall('./miniImagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8725795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and preprocess MiniImageNet dataset\n",
    "transform = transforms.Compose([\n",
    "   # transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Adjust the path to your MiniImageNet dataset directory\n",
    "miniimagenet_path = './miniImagenet/train'\n",
    "dataset = datasets.ImageFolder(miniimagenet_path, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793f0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the dataset\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print('total number of total set: {}'.format(len(dataset)))\n",
    "print('total number of training set: {}'.format(len(train_set)))\n",
    "print('total number of val set: {}'.format(len(val_set)))\n",
    "print('total number of test set: {}'.format(len(test_set)))\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=False)\n",
    "val_loader = DataLoader(val_set, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee9d2aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of total set: 38400\n",
      "total number of training set: 30720\n",
      "total number of test set: 3840\n",
      "total number of val set: 3840\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_set, test_set = train_test_split(dataset, test_size=0.2)\n",
    "val_set, test_set = train_test_split(test_set, test_size=0.5)\n",
    "\n",
    "print('total number of total set: {}'.format(len(dataset)))\n",
    "print('total number of training set: {}'.format(len(train_set)))\n",
    "print('total number of test set: {}'.format(len(test_set)))\n",
    "print('total number of val set: {}'.format(len(val_set)))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(val_set, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb039af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79528940",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(dataset.classes)\n",
    "net = torchvision.models.resnet18(pretrained=False)\n",
    "net.fc = nn.Linear(net.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16efdbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "\n",
    "# evaluation function\n",
    "def eval(net, data_loader):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "    net.eval()\n",
    "    correct = 0.0\n",
    "    num_images = 0.0\n",
    "    for i_batch, (images, labels) in enumerate(data_loader):\n",
    "        if use_cuda:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        outs = net(images) \n",
    "#         _, preds = outs.max(1)\n",
    "        preds = outs.argmax(dim=1)\n",
    "        correct += preds.eq(labels).sum()\n",
    "        num_images += len(labels)\n",
    "\n",
    "    acc = correct / num_images\n",
    "    return acc\n",
    "\n",
    "def train(net, train_loader, valid_loader):\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "        \n",
    "    epoches = 15\n",
    "    for epoch in range(epoches):\n",
    "        net.train()\n",
    "        correct = 0.0 # used to accumulate number of correctly recognized images\n",
    "        num_images = 0.0 # used to accumulate number of images\n",
    "        for i_batch, (images, labels) in enumerate(train_loader):\n",
    "            if use_cuda:\n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outs = net(images) \n",
    "            loss = loss_function(outs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            preds = outs.argmax(dim=1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            num_images += len(labels) \n",
    "        \n",
    "        acc = correct / num_images\n",
    "        acc_eval = eval(net, valid_loader)\n",
    "        print('epoch: %d, lr: %f, accuracy: %f, loss: %f, valid accuracy: %f' % (epoch, optimizer.param_groups[0]['lr'], acc, loss.item(), acc_eval))\n",
    "\n",
    "    return net\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35044c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, lr: 0.010000, accuracy: 0.398210, loss: 2.514230, valid accuracy: 0.305990\n",
      "epoch: 1, lr: 0.010000, accuracy: 0.443457, loss: 1.794717, valid accuracy: 0.292448\n",
      "epoch: 2, lr: 0.010000, accuracy: 0.490853, loss: 1.938201, valid accuracy: 0.297396\n",
      "epoch: 3, lr: 0.010000, accuracy: 0.546322, loss: 1.801848, valid accuracy: 0.299479\n",
      "epoch: 4, lr: 0.010000, accuracy: 0.600846, loss: 1.499800, valid accuracy: 0.322656\n",
      "epoch: 5, lr: 0.010000, accuracy: 0.672493, loss: 1.356383, valid accuracy: 0.316146\n",
      "epoch: 6, lr: 0.010000, accuracy: 0.747591, loss: 0.980958, valid accuracy: 0.334375\n",
      "epoch: 7, lr: 0.010000, accuracy: 0.826628, loss: 0.691682, valid accuracy: 0.334115\n",
      "epoch: 8, lr: 0.010000, accuracy: 0.891927, loss: 0.485882, valid accuracy: 0.304427\n",
      "epoch: 9, lr: 0.010000, accuracy: 0.945508, loss: 0.336064, valid accuracy: 0.345573\n",
      "epoch: 10, lr: 0.010000, accuracy: 0.977344, loss: 0.223478, valid accuracy: 0.334896\n",
      "epoch: 11, lr: 0.010000, accuracy: 0.990299, loss: 0.099559, valid accuracy: 0.339844\n",
      "epoch: 12, lr: 0.010000, accuracy: 0.995573, loss: 0.087456, valid accuracy: 0.342969\n",
      "epoch: 13, lr: 0.010000, accuracy: 0.997233, loss: 0.053873, valid accuracy: 0.352344\n",
      "epoch: 14, lr: 0.010000, accuracy: 0.998828, loss: 0.053379, valid accuracy: 0.353125\n"
     ]
    }
   ],
   "source": [
    "train_net = train(net, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81d80886",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.use_deterministic_algorithms(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec055067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
